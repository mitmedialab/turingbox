{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import csv \n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import get_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AZURE_SUBSCRIPTION_KEY = \"3e8bfdcfae0c41569d5c54ec94e8503a\"\n",
    "AZURE_ENDPOINT = \"https://westus2.api.cognitive.microsoft.com/text/analytics/v2.0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_azure(input_array):\n",
    "        headers = { 'Ocp-Apim-Subscription-Key' : AZURE_SUBSCRIPTION_KEY }\n",
    "        sentiment_api_url =  AZURE_ENDPOINT + \"sentiment\"\n",
    "        docs = []\n",
    "        assert(len(input_array.flatten()) < 1000)\n",
    "        for i, input_text in enumerate(input_array.flatten()):\n",
    "            docs.append({'id' : str(i+1), 'language' : 'en', 'text' : input_text})\n",
    "        documents = { 'documents' : docs }\n",
    "        response = requests.post(sentiment_api_url, headers=headers, json=documents)\n",
    "        sentiments = response.json()\n",
    "        print(sentiments)\n",
    "        scores = [x['score'] for x in sentiments['documents']]\n",
    "        scores = np.array(scores)\n",
    "        return scores.reshape(input_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [{'score': 0.7778275609016418, 'id': '1'}, {'score': 0.7778275609016418, 'id': '2'}], 'errors': []}\n",
      "[0.77782756 0.77782756]\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"this is a text\", \"this is another text\"]\n",
    "input_array = np.array(inputs)\n",
    "result = run(input_array)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(tweet_list, label_list, api_func, save_file): \n",
    "    with open(save_file, 'w') as f: \n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow([\"text\", \"label\", str(api_func)])\n",
    "        sentiment = api_func(np.array(tweet_list))\n",
    "        for i, twt in enumerate(tweet_list): \n",
    "            csv_writer.writerow([twt, label_list[i], sentiment[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'documents': [{'score': 0.9631977081298828, 'id': '1'}, {'score': 0.8952233791351318, 'id': '2'}, {'score': 0.20380455255508423, 'id': '3'}, {'score': 0.16436517238616943, 'id': '4'}, {'score': 0.9923532009124756, 'id': '5'}, {'score': 0.7719802856445312, 'id': '6'}, {'score': 0.8556222915649414, 'id': '7'}, {'score': 0.9133977293968201, 'id': '8'}, {'score': 0.07152354717254639, 'id': '9'}, {'score': 0.7941385507583618, 'id': '10'}, {'score': 0.7449294328689575, 'id': '11'}, {'score': 0.11761602759361267, 'id': '12'}, {'score': 0.5, 'id': '13'}, {'score': 0.9036202430725098, 'id': '14'}, {'score': 0.9851231575012207, 'id': '15'}, {'score': 0.1201251745223999, 'id': '16'}, {'score': 0.8197458982467651, 'id': '17'}, {'score': 0.05911615490913391, 'id': '18'}, {'score': 0.8487657904624939, 'id': '19'}, {'score': 0.20968815684318542, 'id': '20'}, {'score': 0.5, 'id': '21'}, {'score': 0.5, 'id': '22'}, {'score': 0.8717667460441589, 'id': '23'}, {'score': 0.5, 'id': '24'}, {'score': 0.5, 'id': '25'}, {'score': 0.15389519929885864, 'id': '26'}, {'score': 0.28403761982917786, 'id': '27'}, {'score': 0.8664541244506836, 'id': '28'}, {'score': 0.8701887130737305, 'id': '29'}, {'score': 0.9114536643028259, 'id': '30'}, {'score': 0.2450791597366333, 'id': '31'}, {'score': 0.20686575770378113, 'id': '32'}, {'score': 0.9449660778045654, 'id': '33'}, {'score': 0.005578964948654175, 'id': '34'}, {'score': 0.05237853527069092, 'id': '35'}, {'score': 0.8926951289176941, 'id': '36'}, {'score': 0.8967784643173218, 'id': '37'}, {'score': 0.7654719352722168, 'id': '38'}, {'score': 0.9845120906829834, 'id': '39'}, {'score': 0.999065101146698, 'id': '40'}, {'score': 0.9296788573265076, 'id': '41'}, {'score': 0.9957691431045532, 'id': '42'}, {'score': 0.7818424105644226, 'id': '43'}, {'score': 0.05898714065551758, 'id': '44'}, {'score': 0.9740152359008789, 'id': '45'}, {'score': 0.8988368511199951, 'id': '46'}, {'score': 0.02855229377746582, 'id': '47'}, {'score': 0.14913848042488098, 'id': '48'}, {'score': 0.9394224882125854, 'id': '49'}, {'score': 0.7315756678581238, 'id': '50'}, {'score': 0.9541682600975037, 'id': '51'}, {'score': 0.9881469011306763, 'id': '52'}, {'score': 0.7348940968513489, 'id': '53'}, {'score': 0.5, 'id': '54'}, {'score': 0.6939096450805664, 'id': '55'}, {'score': 0.8837939500808716, 'id': '56'}, {'score': 0.21790674328804016, 'id': '57'}, {'score': 0.10419812798500061, 'id': '58'}, {'score': 0.297865092754364, 'id': '59'}, {'score': 0.6877590417861938, 'id': '60'}, {'score': 0.05118560791015625, 'id': '61'}, {'score': 0.872143566608429, 'id': '62'}, {'score': 0.9998260736465454, 'id': '63'}, {'score': 0.9965062737464905, 'id': '64'}, {'score': 0.8420228958129883, 'id': '65'}, {'score': 0.9997963309288025, 'id': '66'}, {'score': 0.04372793436050415, 'id': '67'}, {'score': 0.9737040400505066, 'id': '68'}, {'score': 0.5, 'id': '69'}, {'score': 0.9873303174972534, 'id': '70'}, {'score': 0.7972910404205322, 'id': '71'}, {'score': 0.15547439455986023, 'id': '72'}, {'score': 0.10274600982666016, 'id': '73'}, {'score': 0.9760361313819885, 'id': '74'}, {'score': 0.8644092082977295, 'id': '75'}, {'score': 0.04026186466217041, 'id': '76'}, {'score': 0.16275358200073242, 'id': '77'}, {'score': 0.21754658222198486, 'id': '78'}, {'score': 0.2270786166191101, 'id': '79'}, {'score': 0.003535449504852295, 'id': '80'}, {'score': 0.10102313756942749, 'id': '81'}, {'score': 0.9732495546340942, 'id': '82'}, {'score': 0.24198779463768005, 'id': '83'}, {'score': 0.2440619170665741, 'id': '84'}, {'score': 0.7813631296157837, 'id': '85'}, {'score': 0.16862663626670837, 'id': '86'}, {'score': 0.14665481448173523, 'id': '87'}, {'score': 0.05354267358779907, 'id': '88'}, {'score': 0.19027656316757202, 'id': '89'}, {'score': 0.12302327156066895, 'id': '90'}, {'score': 0.8003566861152649, 'id': '91'}, {'score': 0.9403072595596313, 'id': '92'}, {'score': 0.9032189846038818, 'id': '93'}, {'score': 0.25656992197036743, 'id': '94'}, {'score': 0.8973038792610168, 'id': '95'}, {'score': 0.9957150816917419, 'id': '96'}, {'score': 0.8041485548019409, 'id': '97'}, {'score': 0.16221901774406433, 'id': '98'}, {'score': 0.20014223456382751, 'id': '99'}, {'score': 0.973792314529419, 'id': '100'}], 'errors': []}\n"
     ]
    }
   ],
   "source": [
    "tweets = [] \n",
    "labels = [] \n",
    "\n",
    "with open('datasets/twitter_sentiment100.csv', 'r') as f: \n",
    "    csv_reader = csv.reader(f)\n",
    "    row = next(csv_reader)\n",
    "    for row in csv_reader: \n",
    "        tweets.append(row[0])\n",
    "        labels.append(row[1])\n",
    "\n",
    "write_results(tweets, labels, run_azure, 'results/twitter_sentiment100_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label              0.410000\n",
      "Azure Sentiment    0.570582\n",
      "g_sentiment       -0.025000\n",
      "g_magnitude        0.524000\n",
      "dtype: float64\n",
      "label              0.049431\n",
      "Azure Sentiment    0.034112\n",
      "g_sentiment        0.060275\n",
      "g_magnitude        0.030686\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/sst_sentiment100_results.csv')\n",
    "print(df.mean()) \n",
    "print(df.sem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = df['label'].tolist() \n",
    "pred = df['g_sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.81\n"
     ]
    }
   ],
   "source": [
    "label = np.asarray(label)\n",
    "new_pred = [] \n",
    "for p in pred: \n",
    "    if float(p) > 0: \n",
    "        new_pred.append(1)\n",
    "    else: \n",
    "        new_pred.append(0)\n",
    "pred = np.asarray(new_pred)\n",
    "pred = np.around(pred)\n",
    "acc = np.sum(pred==label)\n",
    "print(\"Accuracy\", acc/len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NB for Amazon Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text'].tolist() \n",
    "labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuning even for the non-gamer : this sound track was beautiful ! it paints the senery in your mind so well i would recomend it even to people who hate vid . game music ! i have played the game chrono cross but out of all of the games i have ever played it has the best music ! it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras . it would impress anyone who cares to listen ! ^_^',\n",
       " \"the best soundtrack ever to anything . : i'm reading a lot of reviews saying that this is the best ' game soundtrack ' and i figured that i'd write a review to disagree a bit . this in my opinino is yasunori mitsuda's ultimate masterpiece . the music is timeless and i'm been listening to it for years now and its beauty simply refuses to fade . the price tag on this is pretty staggering i must say , but if you are going to buy any cd for this much money , this is the only one that i feel would be worth every penny .\",\n",
       " 'amazing ! : this soundtrack is my favorite music of all time , hands down . the intense sadness of \" prisoners of fate \" ( which means all the more if you\\'ve played the game ) and the hope in \" a distant promise \" and \" girl who stole the star \" have been an important inspiration to me personally throughout my teen years . the higher energy tracks like \" chrono cross ~ time\\'s scar ~ \" , \" time of the dreamwatch \" , and \" chronomantique \" ( indefinably remeniscent of chrono trigger ) are all absolutely superb as well . this soundtrack is amazing music , probably the best of this composer\\'s work ( i haven\\'t heard the xenogears soundtrack , so i can\\'t say for sure ) , and even if you\\'ve never played the game , it would be worth twice the price to buy it . i wish i could give it 6 stars .',\n",
       " \"excellent soundtrack : i truly like this soundtrack and i enjoy video game music . i have played this game and most of the music on here i enjoy and it's truly relaxing and peaceful . on disk one . my favorites are scars of time , between life and death , forest of illusion , fortress of ancient dragons , lost fragment , and drowned valley . disk two : the draggons , galdorb - home , chronomantique , prisoners of fate , gale , and my girlfriend likes zelbessdisk three : the best of the three . garden of god , chronopolis , fates , jellyfish sea , burning orphange , dragon's prayer , tower of stars , dragon god , and radical dreamers - unstealable jewel . overall , this is a excellent soundtrack and should be brought by those that like video game music . xander cross\",\n",
       " \"remember , pull your jaw off the floor after hearing it : if you've played the game , you know how divine the music is ! every single song tells a story of the game , it's that good ! the greatest songs are without a doubt , chrono cross : time's scar , magical dreamers : the wind , the stars , and the sea and radical dreamers : unstolen jewel . ( translation varies ) this music is perfect if you ask me , the best it can be . yasunori mitsuda just poured his heart on and wrote it down on paper .\",\n",
       " \"an absolute masterpiece : i am quite sure any of you actually taking the time to read this have played the game at least once , and heard at least a few of the tracks here . and whether you were aware of it or not , mitsuda's music contributed greatly to the mood of every single minute of the whole game . composed of 3 cds and quite a few songs ( i haven't an exact count ) , all of which are heart-rendering and impressively remarkable , this soundtrack is one i assure you you will not forget . it has everything for every listener -- from fast-paced and energetic ( dancing the tokage or termina home ) , to slower and more haunting ( dragon god ) , to purely beautifully composed ( time's scar ) , to even some fantastic vocals ( radical dreamers ) . this is one of the best videogame soundtracks out there , and surely mitsuda's best ever . ^_^\",\n",
       " 'buyer beware : this is a self-published book , and if you want to know why -- read a few paragraphs ! those 5 star reviews must have been written by ms. haddon\\'s family and friends -- or perhaps , by herself ! i can\\'t imagine anyone reading the whole thing -- i spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another . it is most definitely bad enough to be entered into some kind of a \" worst book \" contest . i can\\'t believe amazon even sells this kind of thing . maybe i can offer them my 8 th grade term paper on \" to kill a mockingbird \" -- a book i am quite sure ms. haddon never heard of . anyway , unless you are in a mood to send a book to someone as a joke --- stay far , far away from this one !',\n",
       " 'glorious story : i loved whisper of the wicked saints . the story was amazing and i was pleasantly surprised at the changes in the book . i am not normaly someone who is into romance novels , but the world was raving about this book and so i bought it . i loved it !! this is a brilliant story because it is so true . this book was so wonderful that i have told all of my friends to read it . it is not a typical romance , it is so much more . not reading this book is a crime , becuase you are missing out on a heart warming story .',\n",
       " \"a five star book : i just finished reading whisper of the wicked saints . i fell in love with the caracters . i expected an average romance read , but instead i found one of my favorite books of all time . just when i thought i could predict the outcome i was shocked ! the writting was so descriptive that my heart broke when julia's did and i felt as if i was there with them instead of just a distant reader . if you are a lover of romance novels then this is a must read . don't let the cover fool you this book is spectacular !\",\n",
       " 'whispers of the wicked saints : this was a easy to read book that made me want to keep reading on and on , not easy to put down . it left me wanting to read the follow on , which i hope is coming soon . i used to read a lot but have gotten away from it . this book made me want to read again . very enjoyable .']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000)\n",
    "train_features = vectorizer.fit_transform(texts[1000:9000])\n",
    "print(train_features.shape)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_features, labels[1000:9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('datasets/amazon_sentiment100.csv')\n",
    "test_texts = test_df['text'].tolist() \n",
    "test_labels = test_df['label'].tolist() \n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', vocabulary=vocab)\n",
    "test_features = vectorizer.fit_transform(test_texts)\n",
    "print(test_features.shape)\n",
    "predictions = nb_model.predict(test_features)\n",
    "prob = nb_model.predict_proba(test_features)\n",
    "predictions = nb_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_labels)\n",
    "class_prob = [p[1] for p in prob]\n",
    "nb_model.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4997231513686203\n",
      "0.04644652216476498\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(class_prob))\n",
    "print(np.sqrt(np.var(class_prob)/len(class_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'results/sst_sentiment100_custom_results.csv'\n",
    "with open(save_file, 'w') as f: \n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"text\", \"label\", \"NB_prob\"])\n",
    "    for i, twt in enumerate(test_texts): \n",
    "            csv_writer.writerow([twt, test_labels[i], class_prob[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
